{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from GCForest import gcForest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import Imputer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#用来计算程序运行时间\n",
    "import datetime\n",
    "starttime = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       valence  arousal  dominance  liking  2cArousal  2cValence\n",
      "s01_0     7.71     7.60       6.90    7.83          1          1\n",
      "s01_1     8.10     7.31       7.28    8.47          1          1\n",
      "s01_2     8.58     7.54       9.00    7.08          1          1\n",
      "s01_3     4.94     6.01       6.12    8.06          0          0\n",
      "s01_4     6.96     3.92       7.19    6.05          1          1\n",
      "[seed:0]****************************************************\n",
      "(896, 15744)\n",
      "(384, 15744)\n",
      "(896, 16236)\n",
      "(384, 16236)\n",
      "(896, 16728)\n",
      "(384, 16728)\n",
      "(896, 17220)\n",
      "(384, 17220)\n",
      "Adding/Training Layer, n_layer=1\n",
      "Layer validation accuracy = 0.6666666666666666\n",
      "Adding/Training Layer, n_layer=2\n",
      "Layer validation accuracy = 0.6666666666666666\n",
      "ACC 0.671875\n",
      "F1 0.7613636363636365\n",
      "Recal 0.9262672811059908\n",
      "Precision 0.6463022508038585\n",
      "[seed:100]****************************************************\n",
      "(896, 15744)\n",
      "(384, 15744)\n",
      "(896, 16236)\n",
      "(384, 16236)\n",
      "(896, 16728)\n",
      "(384, 16728)\n",
      "(896, 17220)\n",
      "(384, 17220)\n",
      "Adding/Training Layer, n_layer=1\n",
      "Layer validation accuracy = 0.6555555555555556\n",
      "Adding/Training Layer, n_layer=2\n",
      "Layer validation accuracy = 0.6555555555555556\n",
      "ACC 0.6744791666666666\n",
      "F1 0.7637051039697541\n",
      "Recal 0.9308755760368663\n",
      "Precision 0.6474358974358975\n",
      "[seed:200]****************************************************\n",
      "(896, 15744)\n",
      "(384, 15744)\n",
      "(896, 16236)\n",
      "(384, 16236)\n",
      "(896, 16728)\n",
      "(384, 16728)\n",
      "(896, 17220)\n",
      "(384, 17220)\n",
      "Adding/Training Layer, n_layer=1\n",
      "Layer validation accuracy = 0.6888888888888889\n",
      "Adding/Training Layer, n_layer=2\n",
      "Layer validation accuracy = 0.6888888888888889\n",
      "ACC 0.6744791666666666\n",
      "F1 0.7637051039697541\n",
      "Recal 0.9308755760368663\n",
      "Precision 0.6474358974358975\n",
      "[seed:300]****************************************************\n",
      "(896, 15744)\n",
      "(384, 15744)\n",
      "(896, 16236)\n",
      "(384, 16236)\n",
      "(896, 16728)\n",
      "(384, 16728)\n",
      "(896, 17220)\n",
      "(384, 17220)\n",
      "Adding/Training Layer, n_layer=1\n",
      "Layer validation accuracy = 0.6222222222222222\n",
      "Adding/Training Layer, n_layer=2\n",
      "Layer validation accuracy = 0.6222222222222222\n",
      "ACC 0.671875\n",
      "F1 0.7604562737642586\n",
      "Recal 0.9216589861751152\n",
      "Precision 0.6472491909385113\n",
      "[seed:400]****************************************************\n",
      "(896, 15744)\n",
      "(384, 15744)\n",
      "(896, 16236)\n",
      "(384, 16236)\n",
      "(896, 16728)\n",
      "(384, 16728)\n",
      "(896, 17220)\n",
      "(384, 17220)\n",
      "Adding/Training Layer, n_layer=1\n",
      "Layer validation accuracy = 0.6333333333333333\n",
      "Adding/Training Layer, n_layer=2\n",
      "Layer validation accuracy = 0.6333333333333333\n",
      "ACC 0.6770833333333334\n",
      "F1 0.7624521072796935\n",
      "Recal 0.9170506912442397\n",
      "Precision 0.6524590163934426\n",
      "[seed:500]****************************************************\n",
      "(896, 15744)\n",
      "(384, 15744)\n",
      "(896, 16236)\n",
      "(384, 16236)\n",
      "(896, 16728)\n",
      "(384, 16728)\n",
      "(896, 17220)\n",
      "(384, 17220)\n",
      "Adding/Training Layer, n_layer=1\n",
      "Layer validation accuracy = 0.6444444444444445\n",
      "Adding/Training Layer, n_layer=2\n",
      "Layer validation accuracy = 0.6444444444444445\n",
      "ACC 0.6744791666666666\n",
      "F1 0.7637051039697541\n",
      "Recal 0.9308755760368663\n",
      "Precision 0.6474358974358975\n",
      "[seed:600]****************************************************\n",
      "(896, 15744)\n",
      "(384, 15744)\n",
      "(896, 16236)\n",
      "(384, 16236)\n",
      "(896, 16728)\n",
      "(384, 16728)\n",
      "(896, 17220)\n",
      "(384, 17220)\n",
      "Adding/Training Layer, n_layer=1\n",
      "Layer validation accuracy = 0.6444444444444445\n",
      "Adding/Training Layer, n_layer=2\n",
      "Layer validation accuracy = 0.6444444444444445\n",
      "ACC 0.671875\n",
      "F1 0.7595419847328244\n",
      "Recal 0.9170506912442397\n",
      "Precision 0.6482084690553745\n",
      "[seed:700]****************************************************\n",
      "(896, 15744)\n",
      "(384, 15744)\n",
      "(896, 16236)\n",
      "(384, 16236)\n",
      "(896, 16728)\n",
      "(384, 16728)\n",
      "(896, 17220)\n",
      "(384, 17220)\n",
      "Adding/Training Layer, n_layer=1\n",
      "Layer validation accuracy = 0.7\n",
      "Adding/Training Layer, n_layer=2\n",
      "Layer validation accuracy = 0.7\n",
      "ACC 0.6744791666666666\n",
      "F1 0.7600767754318618\n",
      "Recal 0.9124423963133641\n",
      "Precision 0.6513157894736842\n",
      "[seed:800]****************************************************\n",
      "(896, 15744)\n",
      "(384, 15744)\n",
      "(896, 16236)\n",
      "(384, 16236)\n",
      "(896, 16728)\n",
      "(384, 16728)\n",
      "(896, 17220)\n",
      "(384, 17220)\n",
      "Adding/Training Layer, n_layer=1\n",
      "Layer validation accuracy = 0.6666666666666666\n",
      "Adding/Training Layer, n_layer=2\n",
      "Layer validation accuracy = 0.6666666666666666\n",
      "ACC 0.6744791666666666\n",
      "F1 0.761904761904762\n",
      "Recal 0.9216589861751152\n",
      "Precision 0.6493506493506493\n",
      "[seed:900]****************************************************\n",
      "(896, 15744)\n",
      "(384, 15744)\n",
      "(896, 16236)\n",
      "(384, 16236)\n",
      "(896, 16728)\n",
      "(384, 16728)\n",
      "(896, 17220)\n",
      "(384, 17220)\n",
      "Adding/Training Layer, n_layer=1\n",
      "Layer validation accuracy = 0.6333333333333333\n",
      "Adding/Training Layer, n_layer=2\n",
      "Layer validation accuracy = 0.6333333333333333\n",
      "ACC 0.671875\n",
      "F1 0.7613636363636365\n",
      "Recal 0.9262672811059908\n",
      "Precision 0.6463022508038585\n"
     ]
    }
   ],
   "source": [
    "#读取Y\n",
    "all_df_y = pickle.load(open(\"./dump_file/all_df_y\",\"rb\"))\n",
    "all_df_y['2cArousal'] = 0\n",
    "all_df_y['2cArousal'][all_df_y['valence'] >= 5] = 1\n",
    "all_df_y['2cValence'] = 0\n",
    "all_df_y['2cValence'][all_df_y['valence'] >= 5] = 1\n",
    "print(all_df_y.head(5))\n",
    "\n",
    "y = all_df_y[['2cValence']]\n",
    "#y = all_df_y[[\"2cArousal\"]]\n",
    "for seed in [0,100,200,300,400,500,600,700,800,900]:\n",
    "    print(\"[seed:{}]****************************************************\".format(seed))\n",
    "    xTrainIdx = pickle.load(open(\"./dump_file/xTrainIdx\",\"rb\"))\n",
    "    xTestIdx = pickle.load(open(\"./dump_file/xTestIdx\",\"rb\"))\n",
    "    y_tr = y.loc[xTrainIdx]\n",
    "    y_te = y.loc[xTestIdx]\n",
    "\n",
    "    myWindowsSize = 256\n",
    "    myStrideSize = 64\n",
    "    gcf = gcForest(shape_1X=8064, window=myWindowsSize, stride=myStrideSize,tolerance=0.0,n_cascadeRF=1, \n",
    "                   min_samples_mgs=0.2, min_samples_cascade=0.2,cascade_layer = 5,cascade_test_size = 0.1\n",
    "                   ,n_jobs=19)\n",
    "\n",
    "    #这部分是时域的\n",
    "    for eegCH in range(1,33,1):\n",
    "        filePath = \"./dump_file/CH{}mgsTrainVector_{}_{}_{}\".format(eegCH,myWindowsSize,myStrideSize,seed)\n",
    "        locals()['CH{}mgsTrainVector'.format(eegCH)] = pickle.load(open(filePath,\"rb\"))\n",
    "        filePath = \"./dump_file/CH{}mgsTestVector_{}_{}_{}\".format(eegCH,myWindowsSize,myStrideSize,seed)\n",
    "        locals()['CH{}mgsTestVector'.format(eegCH)]= pickle.load(open(filePath,\"rb\"))\n",
    "    X_tr_vector = locals()['CH{}mgsTrainVector'.format(1)]\n",
    "    X_te_vector = locals()['CH{}mgsTestVector'.format(1)]\n",
    "    #拼接MGS处理的各个通道向量---》cascade forest\n",
    "    for eegCH in range(2,33,1):\n",
    "        nextTrainVector = locals()['CH{}mgsTrainVector'.format(eegCH)]\n",
    "        nextTestVector = locals()['CH{}mgsTestVector'.format(eegCH)]\n",
    "        X_tr_vector = np.concatenate([X_tr_vector,nextTrainVector],axis=1)\n",
    "        X_te_vector = np.concatenate([X_te_vector,nextTestVector],axis=1)\n",
    "    print(X_tr_vector.shape)\n",
    "    print(X_te_vector.shape)\n",
    "\n",
    "    #这部分是频域的\n",
    "    if False:\n",
    "        for eegCH in range(1,33,1):\n",
    "            filePath = \"./dump_file_V2/CH{}mgsTrainVector_{}_{}_{}\".format(eegCH,myWindowsSize,myStrideSize,seed)\n",
    "            locals()['CH{}mgsTrainVector'.format(eegCH)] = pickle.load(open(filePath,\"rb\"))\n",
    "            filePath = \"./dump_file_V2/CH{}mgsTestVector_{}_{}_{}\".format(eegCH,myWindowsSize,myStrideSize,seed)\n",
    "            locals()['CH{}mgsTestVector'.format(eegCH)]= pickle.load(open(filePath,\"rb\"))\\\n",
    "        #在已经有时域数据的基础上拼接MGS处理的各个通道向量---》cascade forest\n",
    "        for eegCH in range(1,33,1):\n",
    "            nextTrainVector = locals()['CH{}mgsTrainVector'.format(eegCH)]\n",
    "            nextTestVector = locals()['CH{}mgsTestVector'.format(eegCH)]\n",
    "            X_tr_vector = np.concatenate([X_tr_vector,nextTrainVector],axis=1)\n",
    "            X_te_vector = np.concatenate([X_te_vector,nextTestVector],axis=1)\n",
    "        print(X_tr_vector.shape)\n",
    "        print(X_te_vector.shape)\n",
    "\n",
    "    #这部分是BVP\n",
    "    filePath = \"./dump_file_V2/BVP_mgsTrainVector_{}_{}_{}\".format(myWindowsSize,myStrideSize,seed)\n",
    "    BVP_mgsTrainVector = pickle.load(open(filePath,\"rb\"))\n",
    "    filePath = \"./dump_file_V2/BVP_mgsTestVector_{}_{}_{}\".format(myWindowsSize,myStrideSize,seed)\n",
    "    BVP_mgsTestVector = pickle.load(open(filePath,\"rb\"))\n",
    "    X_tr_vector = np.concatenate([X_tr_vector,BVP_mgsTrainVector],axis=1)\n",
    "    X_te_vector = np.concatenate([X_te_vector,BVP_mgsTestVector],axis=1)\n",
    "    print(X_tr_vector.shape)\n",
    "    print(X_te_vector.shape)\n",
    "    #这部分是RSP\n",
    "    filePath = \"./dump_file_V2/RSP_mgsTrainVector_{}_{}_{}\".format(myWindowsSize,myStrideSize,seed)\n",
    "    RSP_mgsTrainVector = pickle.load(open(filePath,\"rb\"))\n",
    "    filePath = \"./dump_file_V2/RSP_mgsTestVector_{}_{}_{}\".format(myWindowsSize,myStrideSize,seed)\n",
    "    RSP_mgsTestVector = pickle.load(open(filePath,\"rb\"))\n",
    "    X_tr_vector = np.concatenate([X_tr_vector,RSP_mgsTrainVector],axis=1)\n",
    "    X_te_vector = np.concatenate([X_te_vector,RSP_mgsTestVector],axis=1)\n",
    "    print(X_tr_vector.shape)\n",
    "    print(X_te_vector.shape)\n",
    "    #这部分是GSR\n",
    "    filePath = \"./dump_file_V2/GSR_mgsTrainVector_{}_{}_{}\".format(myWindowsSize,myStrideSize,seed)\n",
    "    RSP_mgsTrainVector = pickle.load(open(filePath,\"rb\"))\n",
    "    filePath = \"./dump_file_V2/GSR_mgsTestVector_{}_{}_{}\".format(myWindowsSize,myStrideSize,seed)\n",
    "    RSP_mgsTestVector = pickle.load(open(filePath,\"rb\"))\n",
    "    X_tr_vector = np.concatenate([X_tr_vector,RSP_mgsTrainVector],axis=1)\n",
    "    X_te_vector = np.concatenate([X_te_vector,RSP_mgsTestVector],axis=1)\n",
    "    print(X_tr_vector.shape)\n",
    "    print(X_te_vector.shape)\n",
    "    #如有缺失值，填充下\n",
    "    X_tr_vector_fillna= pd.DataFrame(X_tr_vector).fillna(0).values\n",
    "    X_te_vector_fillna= pd.DataFrame(X_te_vector).fillna(0).values\n",
    "    _ = gcf.cascade_forest(X_tr_vector_fillna, y_tr)\n",
    "    pred_proba = gcf.cascade_forest(X_te_vector_fillna)\n",
    "    tmp = np.mean(pred_proba, axis=0)\n",
    "    preds = np.argmax(tmp, axis=1)\n",
    "    print(\"ACC\",accuracy_score(y_true=y_te, y_pred=preds))\n",
    "    print(\"F1\",f1_score(y_true=y_te, y_pred=preds))\n",
    "    print(\"Recal\",recall_score(y_true=y_te, y_pred=preds))\n",
    "    print(\"Precision\",precision_score(y_true=y_te, y_pred=preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
